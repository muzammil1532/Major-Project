{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c9ab66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd  #Data manipulation and analysis\n",
    "import numpy as np   #Performs high level manipulation\n",
    "import sklearn   # provides efficient tools for predictive data analysis\n",
    "\n",
    "# Preprocessing purpose\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# For getting the importances\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Feature Extraction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Splitting Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For accuracy,Classification Report, Confusion Matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "# For training different ML models\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f57f851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading datasets for training,testing and prediction\n",
    "train = pd.read_csv('E:/MajorProject/Code/DataSet1/UNSW_NB15_training-set.csv')\n",
    "test = pd.read_csv('E:/MajorProject/Code/DataSet1/UNSW_NB15_testing-set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e85c793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id       dur proto service state  spkts  dpkts  sbytes  dbytes  \\\n",
      "0   1  0.000011   udp       -   INT      2      0     496       0   \n",
      "1   2  0.000008   udp       -   INT      2      0    1762       0   \n",
      "2   3  0.000005   udp       -   INT      2      0    1068       0   \n",
      "3   4  0.000006   udp       -   INT      2      0     900       0   \n",
      "4   5  0.000010   udp       -   INT      2      0    2126       0   \n",
      "\n",
      "          rate  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
      "0   90909.0902  ...                 1               2             0   \n",
      "1  125000.0003  ...                 1               2             0   \n",
      "2  200000.0051  ...                 1               3             0   \n",
      "3  166666.6608  ...                 1               3             0   \n",
      "4  100000.0025  ...                 1               3             0   \n",
      "\n",
      "   ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \\\n",
      "0           0                 0           1           2                0   \n",
      "1           0                 0           1           2                0   \n",
      "2           0                 0           1           3                0   \n",
      "3           0                 0           2           3                0   \n",
      "4           0                 0           2           3                0   \n",
      "\n",
      "   attack_cat  label  \n",
      "0      Normal      0  \n",
      "1      Normal      0  \n",
      "2      Normal      0  \n",
      "3      Normal      0  \n",
      "4      Normal      0  \n",
      "\n",
      "[5 rows x 45 columns]\n",
      "Training data has 82332 rows & 45 columns\n"
     ]
    }
   ],
   "source": [
    "# Display initial training data\n",
    "print(train.head())\n",
    "print(\"Training data has {} rows & {} columns\".format(train.shape[0],train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87a859b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id       dur proto service state  spkts  dpkts  sbytes  dbytes       rate  \\\n",
      "0   1  0.121478   tcp       -   FIN      6      4     258     172  74.087490   \n",
      "1   2  0.649902   tcp       -   FIN     14     38     734   42014  78.473372   \n",
      "2   3  1.623129   tcp       -   FIN      8     16     364   13186  14.170161   \n",
      "3   4  1.681642   tcp     ftp   FIN     12     12     628     770  13.677108   \n",
      "4   5  0.449454   tcp       -   FIN     10      6     534     268  33.373826   \n",
      "\n",
      "   ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  \\\n",
      "0  ...                 1               1             0           0   \n",
      "1  ...                 1               2             0           0   \n",
      "2  ...                 1               3             0           0   \n",
      "3  ...                 1               3             1           1   \n",
      "4  ...                 1              40             0           0   \n",
      "\n",
      "   ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  attack_cat  \\\n",
      "0                 0           1           1                0      Normal   \n",
      "1                 0           1           6                0      Normal   \n",
      "2                 0           2           6                0      Normal   \n",
      "3                 0           2           1                0      Normal   \n",
      "4                 0           2          39                0      Normal   \n",
      "\n",
      "   label  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "3      0  \n",
      "4      0  \n",
      "\n",
      "[5 rows x 45 columns]\n",
      "Testing data has 175341 rows & 45 columns\n"
     ]
    }
   ],
   "source": [
    "#Display initial Testing Data\n",
    "print(test.head())\n",
    "print(\"Testing data has {} rows & {} columns\".format(test.shape[0],test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14437300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dur</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>82332.000000</td>\n",
       "      <td>82332.000000</td>\n",
       "      <td>82332.000000</td>\n",
       "      <td>82332.000000</td>\n",
       "      <td>8.233200e+04</td>\n",
       "      <td>8.233200e+04</td>\n",
       "      <td>8.233200e+04</td>\n",
       "      <td>82332.000000</td>\n",
       "      <td>82332.000000</td>\n",
       "      <td>8.233200e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>82332.000000</td>\n",
       "      <td>82332.000000</td>\n",
       "      <td>82332.000000</td>\n",
       "      <td>82332.000000</td>\n",
       "      <td>82332.000000</td>\n",
       "      <td>82332.000000</td>\n",
       "      <td>82332.000000</td>\n",
       "      <td>82332.000000</td>\n",
       "      <td>82332.000000</td>\n",
       "      <td>82332.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41166.500000</td>\n",
       "      <td>1.006756</td>\n",
       "      <td>18.666472</td>\n",
       "      <td>17.545936</td>\n",
       "      <td>7.993908e+03</td>\n",
       "      <td>1.323379e+04</td>\n",
       "      <td>8.241089e+04</td>\n",
       "      <td>180.967667</td>\n",
       "      <td>95.713003</td>\n",
       "      <td>6.454902e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>4.928898</td>\n",
       "      <td>3.663011</td>\n",
       "      <td>7.456360</td>\n",
       "      <td>0.008284</td>\n",
       "      <td>0.008381</td>\n",
       "      <td>0.129743</td>\n",
       "      <td>6.468360</td>\n",
       "      <td>9.164262</td>\n",
       "      <td>0.011126</td>\n",
       "      <td>0.550600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>23767.345519</td>\n",
       "      <td>4.710444</td>\n",
       "      <td>133.916353</td>\n",
       "      <td>115.574086</td>\n",
       "      <td>1.716423e+05</td>\n",
       "      <td>1.514715e+05</td>\n",
       "      <td>1.486204e+05</td>\n",
       "      <td>101.513358</td>\n",
       "      <td>116.667722</td>\n",
       "      <td>1.798618e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>8.389545</td>\n",
       "      <td>5.915386</td>\n",
       "      <td>11.415191</td>\n",
       "      <td>0.091171</td>\n",
       "      <td>0.092485</td>\n",
       "      <td>0.638683</td>\n",
       "      <td>8.543927</td>\n",
       "      <td>11.121413</td>\n",
       "      <td>0.104891</td>\n",
       "      <td>0.497436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20583.750000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.140000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.860611e+01</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.120247e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>41166.500000</td>\n",
       "      <td>0.014138</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.340000e+02</td>\n",
       "      <td>1.780000e+02</td>\n",
       "      <td>2.650177e+03</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.770032e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61749.250000</td>\n",
       "      <td>0.719360</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.280000e+03</td>\n",
       "      <td>9.560000e+02</td>\n",
       "      <td>1.111111e+05</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>6.514286e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>82332.000000</td>\n",
       "      <td>59.999989</td>\n",
       "      <td>10646.000000</td>\n",
       "      <td>11018.000000</td>\n",
       "      <td>1.435577e+07</td>\n",
       "      <td>1.465753e+07</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>5.268000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id           dur         spkts         dpkts        sbytes  \\\n",
       "count  82332.000000  82332.000000  82332.000000  82332.000000  8.233200e+04   \n",
       "mean   41166.500000      1.006756     18.666472     17.545936  7.993908e+03   \n",
       "std    23767.345519      4.710444    133.916353    115.574086  1.716423e+05   \n",
       "min        1.000000      0.000000      1.000000      0.000000  2.400000e+01   \n",
       "25%    20583.750000      0.000008      2.000000      0.000000  1.140000e+02   \n",
       "50%    41166.500000      0.014138      6.000000      2.000000  5.340000e+02   \n",
       "75%    61749.250000      0.719360     12.000000     10.000000  1.280000e+03   \n",
       "max    82332.000000     59.999989  10646.000000  11018.000000  1.435577e+07   \n",
       "\n",
       "             dbytes          rate          sttl          dttl         sload  \\\n",
       "count  8.233200e+04  8.233200e+04  82332.000000  82332.000000  8.233200e+04   \n",
       "mean   1.323379e+04  8.241089e+04    180.967667     95.713003  6.454902e+07   \n",
       "std    1.514715e+05  1.486204e+05    101.513358    116.667722  1.798618e+08   \n",
       "min    0.000000e+00  0.000000e+00      0.000000      0.000000  0.000000e+00   \n",
       "25%    0.000000e+00  2.860611e+01     62.000000      0.000000  1.120247e+04   \n",
       "50%    1.780000e+02  2.650177e+03    254.000000     29.000000  5.770032e+05   \n",
       "75%    9.560000e+02  1.111111e+05    254.000000    252.000000  6.514286e+07   \n",
       "max    1.465753e+07  1.000000e+06    255.000000    253.000000  5.268000e+09   \n",
       "\n",
       "       ...  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
       "count  ...      82332.000000      82332.000000    82332.000000  82332.000000   \n",
       "mean   ...          4.928898          3.663011        7.456360      0.008284   \n",
       "std    ...          8.389545          5.915386       11.415191      0.091171   \n",
       "min    ...          1.000000          1.000000        1.000000      0.000000   \n",
       "25%    ...          1.000000          1.000000        1.000000      0.000000   \n",
       "50%    ...          1.000000          1.000000        3.000000      0.000000   \n",
       "75%    ...          4.000000          3.000000        6.000000      0.000000   \n",
       "max    ...         59.000000         38.000000       63.000000      2.000000   \n",
       "\n",
       "         ct_ftp_cmd  ct_flw_http_mthd    ct_src_ltm    ct_srv_dst  \\\n",
       "count  82332.000000      82332.000000  82332.000000  82332.000000   \n",
       "mean       0.008381          0.129743      6.468360      9.164262   \n",
       "std        0.092485          0.638683      8.543927     11.121413   \n",
       "min        0.000000          0.000000      1.000000      1.000000   \n",
       "25%        0.000000          0.000000      1.000000      2.000000   \n",
       "50%        0.000000          0.000000      3.000000      5.000000   \n",
       "75%        0.000000          0.000000      7.000000     11.000000   \n",
       "max        2.000000         16.000000     60.000000     62.000000   \n",
       "\n",
       "       is_sm_ips_ports         label  \n",
       "count     82332.000000  82332.000000  \n",
       "mean          0.011126      0.550600  \n",
       "std           0.104891      0.497436  \n",
       "min           0.000000      0.000000  \n",
       "25%           0.000000      0.000000  \n",
       "50%           0.000000      1.000000  \n",
       "75%           0.000000      1.000000  \n",
       "max           1.000000      1.000000  \n",
       "\n",
       "[8 rows x 41 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6ef74e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dur</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>175341.000000</td>\n",
       "      <td>175341.000000</td>\n",
       "      <td>175341.000000</td>\n",
       "      <td>175341.000000</td>\n",
       "      <td>1.753410e+05</td>\n",
       "      <td>1.753410e+05</td>\n",
       "      <td>1.753410e+05</td>\n",
       "      <td>175341.000000</td>\n",
       "      <td>175341.000000</td>\n",
       "      <td>1.753410e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>175341.000000</td>\n",
       "      <td>175341.000000</td>\n",
       "      <td>175341.000000</td>\n",
       "      <td>175341.000000</td>\n",
       "      <td>175341.000000</td>\n",
       "      <td>175341.000000</td>\n",
       "      <td>175341.000000</td>\n",
       "      <td>175341.000000</td>\n",
       "      <td>175341.000000</td>\n",
       "      <td>175341.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>87671.000000</td>\n",
       "      <td>1.359389</td>\n",
       "      <td>20.298664</td>\n",
       "      <td>18.969591</td>\n",
       "      <td>8.844844e+03</td>\n",
       "      <td>1.492892e+04</td>\n",
       "      <td>9.540619e+04</td>\n",
       "      <td>179.546997</td>\n",
       "      <td>79.609567</td>\n",
       "      <td>7.345403e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>5.383538</td>\n",
       "      <td>4.206255</td>\n",
       "      <td>8.729881</td>\n",
       "      <td>0.014948</td>\n",
       "      <td>0.014948</td>\n",
       "      <td>0.133066</td>\n",
       "      <td>6.955789</td>\n",
       "      <td>9.100758</td>\n",
       "      <td>0.015752</td>\n",
       "      <td>0.680622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>50616.731112</td>\n",
       "      <td>6.480249</td>\n",
       "      <td>136.887597</td>\n",
       "      <td>110.258271</td>\n",
       "      <td>1.747656e+05</td>\n",
       "      <td>1.436542e+05</td>\n",
       "      <td>1.654010e+05</td>\n",
       "      <td>102.940011</td>\n",
       "      <td>110.506863</td>\n",
       "      <td>1.883574e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>8.047104</td>\n",
       "      <td>5.783585</td>\n",
       "      <td>10.956186</td>\n",
       "      <td>0.126048</td>\n",
       "      <td>0.126048</td>\n",
       "      <td>0.701208</td>\n",
       "      <td>8.321493</td>\n",
       "      <td>10.756952</td>\n",
       "      <td>0.124516</td>\n",
       "      <td>0.466237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.800000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>43836.000000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.140000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.278614e+01</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.305334e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>87671.000000</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.300000e+02</td>\n",
       "      <td>1.640000e+02</td>\n",
       "      <td>3.225807e+03</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>8.796748e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>131506.000000</td>\n",
       "      <td>0.668069</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.418000e+03</td>\n",
       "      <td>1.102000e+03</td>\n",
       "      <td>1.250000e+05</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>8.888889e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>175341.000000</td>\n",
       "      <td>59.999989</td>\n",
       "      <td>9616.000000</td>\n",
       "      <td>10974.000000</td>\n",
       "      <td>1.296523e+07</td>\n",
       "      <td>1.465555e+07</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>5.988000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id            dur          spkts          dpkts  \\\n",
       "count  175341.000000  175341.000000  175341.000000  175341.000000   \n",
       "mean    87671.000000       1.359389      20.298664      18.969591   \n",
       "std     50616.731112       6.480249     136.887597     110.258271   \n",
       "min         1.000000       0.000000       1.000000       0.000000   \n",
       "25%     43836.000000       0.000008       2.000000       0.000000   \n",
       "50%     87671.000000       0.001582       2.000000       2.000000   \n",
       "75%    131506.000000       0.668069      12.000000      10.000000   \n",
       "max    175341.000000      59.999989    9616.000000   10974.000000   \n",
       "\n",
       "             sbytes        dbytes          rate           sttl           dttl  \\\n",
       "count  1.753410e+05  1.753410e+05  1.753410e+05  175341.000000  175341.000000   \n",
       "mean   8.844844e+03  1.492892e+04  9.540619e+04     179.546997      79.609567   \n",
       "std    1.747656e+05  1.436542e+05  1.654010e+05     102.940011     110.506863   \n",
       "min    2.800000e+01  0.000000e+00  0.000000e+00       0.000000       0.000000   \n",
       "25%    1.140000e+02  0.000000e+00  3.278614e+01      62.000000       0.000000   \n",
       "50%    4.300000e+02  1.640000e+02  3.225807e+03     254.000000      29.000000   \n",
       "75%    1.418000e+03  1.102000e+03  1.250000e+05     254.000000     252.000000   \n",
       "max    1.296523e+07  1.465555e+07  1.000000e+06     255.000000     254.000000   \n",
       "\n",
       "              sload  ...  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  \\\n",
       "count  1.753410e+05  ...     175341.000000     175341.000000   175341.000000   \n",
       "mean   7.345403e+07  ...          5.383538          4.206255        8.729881   \n",
       "std    1.883574e+08  ...          8.047104          5.783585       10.956186   \n",
       "min    0.000000e+00  ...          1.000000          1.000000        1.000000   \n",
       "25%    1.305334e+04  ...          1.000000          1.000000        1.000000   \n",
       "50%    8.796748e+05  ...          1.000000          1.000000        3.000000   \n",
       "75%    8.888889e+07  ...          5.000000          3.000000       12.000000   \n",
       "max    5.988000e+09  ...         51.000000         46.000000       65.000000   \n",
       "\n",
       "        is_ftp_login     ct_ftp_cmd  ct_flw_http_mthd     ct_src_ltm  \\\n",
       "count  175341.000000  175341.000000     175341.000000  175341.000000   \n",
       "mean        0.014948       0.014948          0.133066       6.955789   \n",
       "std         0.126048       0.126048          0.701208       8.321493   \n",
       "min         0.000000       0.000000          0.000000       1.000000   \n",
       "25%         0.000000       0.000000          0.000000       2.000000   \n",
       "50%         0.000000       0.000000          0.000000       3.000000   \n",
       "75%         0.000000       0.000000          0.000000       9.000000   \n",
       "max         4.000000       4.000000         30.000000      60.000000   \n",
       "\n",
       "          ct_srv_dst  is_sm_ips_ports          label  \n",
       "count  175341.000000    175341.000000  175341.000000  \n",
       "mean        9.100758         0.015752       0.680622  \n",
       "std        10.756952         0.124516       0.466237  \n",
       "min         1.000000         0.000000       0.000000  \n",
       "25%         2.000000         0.000000       0.000000  \n",
       "50%         4.000000         0.000000       1.000000  \n",
       "75%        12.000000         0.000000       1.000000  \n",
       "max        62.000000         1.000000       1.000000  \n",
       "\n",
       "[8 rows x 41 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35eabb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total attack categories and count in training data\n",
      "\n",
      "Normal            37000\n",
      "Generic           18871\n",
      "Exploits          11132\n",
      "Fuzzers            6062\n",
      "DoS                4089\n",
      "Reconnaissance     3496\n",
      "Analysis            677\n",
      "Backdoor            583\n",
      "Shellcode           378\n",
      "Worms                44\n",
      "Name: attack_cat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total attack categories and count in training data')\n",
    "print()\n",
    "print(train['attack_cat'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e18ada2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total attack categories and count in testing data\n",
      "\n",
      "Normal            56000\n",
      "Generic           40000\n",
      "Exploits          33393\n",
      "Fuzzers           18184\n",
      "DoS               12264\n",
      "Reconnaissance    10491\n",
      "Analysis           2000\n",
      "Backdoor           1746\n",
      "Shellcode          1133\n",
      "Worms               130\n",
      "Name: attack_cat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total attack categories and count in testing data')\n",
    "print()\n",
    "print(test['attack_cat'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af995a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin', 'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth', 'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm', 'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat', 'label']\n",
      "\n",
      "['dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin', 'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth', 'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm', 'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat', 'label']\n"
     ]
    }
   ],
   "source": [
    "#id column is of no use so drop it\n",
    "train.drop(['id'],axis=1,inplace=True)\n",
    "test.drop(['id'],axis=1,inplace=True)\n",
    "print(list(train.columns))\n",
    "print()\n",
    "print(list(test.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa7d83a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# extract numerical attributes and scale it to have zero mean and unit variance  \n",
    "cols = train.select_dtypes(include=['float64','int64']).columns\n",
    "sc_train = scaler.fit_transform(train.select_dtypes(include=['float64','int64']))\n",
    "sc_test = scaler.fit_transform(test.select_dtypes(include=['float64','int64']))\n",
    "\n",
    "# turn the result back to a dataframe\n",
    "sc_traindf = pd.DataFrame(sc_train, columns = cols)\n",
    "sc_testdf = pd.DataFrame(sc_test, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7469313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>dload</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.233200e+04</td>\n",
       "      <td>8.233200e+04</td>\n",
       "      <td>8.233200e+04</td>\n",
       "      <td>8.233200e+04</td>\n",
       "      <td>8.233200e+04</td>\n",
       "      <td>8.233200e+04</td>\n",
       "      <td>8.233200e+04</td>\n",
       "      <td>8.233200e+04</td>\n",
       "      <td>8.233200e+04</td>\n",
       "      <td>8.233200e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>8.233200e+04</td>\n",
       "      <td>8.233200e+04</td>\n",
       "      <td>8.233200e+04</td>\n",
       "      <td>8.233200e+04</td>\n",
       "      <td>8.233200e+04</td>\n",
       "      <td>8.233200e+04</td>\n",
       "      <td>8.233200e+04</td>\n",
       "      <td>8.233200e+04</td>\n",
       "      <td>8.233200e+04</td>\n",
       "      <td>8.233200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.184270e-16</td>\n",
       "      <td>-2.096649e-15</td>\n",
       "      <td>-1.698501e-14</td>\n",
       "      <td>3.414023e-16</td>\n",
       "      <td>-1.044781e-14</td>\n",
       "      <td>2.271449e-15</td>\n",
       "      <td>-1.620620e-13</td>\n",
       "      <td>1.533671e-13</td>\n",
       "      <td>-6.077996e-15</td>\n",
       "      <td>3.152681e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.653541e-14</td>\n",
       "      <td>-1.402275e-13</td>\n",
       "      <td>-3.511471e-14</td>\n",
       "      <td>5.131522e-15</td>\n",
       "      <td>-6.061971e-14</td>\n",
       "      <td>-2.793963e-14</td>\n",
       "      <td>-5.055105e-14</td>\n",
       "      <td>-2.861381e-14</td>\n",
       "      <td>7.580418e-14</td>\n",
       "      <td>4.793738e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000006e+00</td>\n",
       "      <td>1.000006e+00</td>\n",
       "      <td>1.000006e+00</td>\n",
       "      <td>1.000006e+00</td>\n",
       "      <td>1.000006e+00</td>\n",
       "      <td>1.000006e+00</td>\n",
       "      <td>1.000006e+00</td>\n",
       "      <td>1.000006e+00</td>\n",
       "      <td>1.000006e+00</td>\n",
       "      <td>1.000006e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000006e+00</td>\n",
       "      <td>1.000006e+00</td>\n",
       "      <td>1.000006e+00</td>\n",
       "      <td>1.000006e+00</td>\n",
       "      <td>1.000006e+00</td>\n",
       "      <td>1.000006e+00</td>\n",
       "      <td>1.000006e+00</td>\n",
       "      <td>1.000006e+00</td>\n",
       "      <td>1.000006e+00</td>\n",
       "      <td>1.000006e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.137298e-01</td>\n",
       "      <td>-1.319225e-01</td>\n",
       "      <td>-1.518164e-01</td>\n",
       "      <td>-4.643353e-02</td>\n",
       "      <td>-8.736871e-02</td>\n",
       "      <td>-5.545094e-01</td>\n",
       "      <td>-1.782709e+00</td>\n",
       "      <td>-8.203947e-01</td>\n",
       "      <td>-3.588833e-01</td>\n",
       "      <td>-2.634980e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.683116e-01</td>\n",
       "      <td>-4.501865e-01</td>\n",
       "      <td>-5.655971e-01</td>\n",
       "      <td>-9.085748e-02</td>\n",
       "      <td>-9.061736e-02</td>\n",
       "      <td>-2.031428e-01</td>\n",
       "      <td>-6.400328e-01</td>\n",
       "      <td>-7.341074e-01</td>\n",
       "      <td>-1.060701e-01</td>\n",
       "      <td>-1.106883e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-2.137281e-01</td>\n",
       "      <td>-1.244551e-01</td>\n",
       "      <td>-1.518164e-01</td>\n",
       "      <td>-4.590918e-02</td>\n",
       "      <td>-8.736871e-02</td>\n",
       "      <td>-5.543169e-01</td>\n",
       "      <td>-1.171948e+00</td>\n",
       "      <td>-8.203947e-01</td>\n",
       "      <td>-3.588210e-01</td>\n",
       "      <td>-2.634980e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.683116e-01</td>\n",
       "      <td>-4.501865e-01</td>\n",
       "      <td>-5.655971e-01</td>\n",
       "      <td>-9.085748e-02</td>\n",
       "      <td>-9.061736e-02</td>\n",
       "      <td>-2.031428e-01</td>\n",
       "      <td>-6.400328e-01</td>\n",
       "      <td>-6.441902e-01</td>\n",
       "      <td>-1.060701e-01</td>\n",
       "      <td>-1.106883e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.107283e-01</td>\n",
       "      <td>-9.458553e-02</td>\n",
       "      <td>-1.345114e-01</td>\n",
       "      <td>-4.346222e-02</td>\n",
       "      <td>-8.619357e-02</td>\n",
       "      <td>-5.366774e-01</td>\n",
       "      <td>7.194401e-01</td>\n",
       "      <td>-5.718240e-01</td>\n",
       "      <td>-3.556752e-01</td>\n",
       "      <td>-2.626150e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.683116e-01</td>\n",
       "      <td>-4.501865e-01</td>\n",
       "      <td>-3.903909e-01</td>\n",
       "      <td>-9.085748e-02</td>\n",
       "      <td>-9.061736e-02</td>\n",
       "      <td>-2.031428e-01</td>\n",
       "      <td>-4.059469e-01</td>\n",
       "      <td>-3.744387e-01</td>\n",
       "      <td>-1.060701e-01</td>\n",
       "      <td>9.034381e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-6.101285e-02</td>\n",
       "      <td>-4.978117e-02</td>\n",
       "      <td>-6.529130e-02</td>\n",
       "      <td>-3.911594e-02</td>\n",
       "      <td>-8.105725e-02</td>\n",
       "      <td>1.931121e-01</td>\n",
       "      <td>7.194401e-01</td>\n",
       "      <td>1.339599e+00</td>\n",
       "      <td>3.301660e-03</td>\n",
       "      <td>-2.568711e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.107215e-01</td>\n",
       "      <td>-1.120831e-01</td>\n",
       "      <td>-1.275816e-01</td>\n",
       "      <td>-9.085748e-02</td>\n",
       "      <td>-9.061736e-02</td>\n",
       "      <td>-2.031428e-01</td>\n",
       "      <td>6.222472e-02</td>\n",
       "      <td>1.650644e-01</td>\n",
       "      <td>-1.060701e-01</td>\n",
       "      <td>9.034381e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.252400e+01</td>\n",
       "      <td>7.935848e+01</td>\n",
       "      <td>9.518155e+01</td>\n",
       "      <td>8.359169e+01</td>\n",
       "      <td>9.668083e+01</td>\n",
       "      <td>6.174084e+00</td>\n",
       "      <td>7.292910e-01</td>\n",
       "      <td>1.348170e+00</td>\n",
       "      <td>2.893044e+01</td>\n",
       "      <td>8.437392e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>6.445097e+00</td>\n",
       "      <td>5.804726e+00</td>\n",
       "      <td>4.865795e+00</td>\n",
       "      <td>2.184603e+01</td>\n",
       "      <td>2.153462e+01</td>\n",
       "      <td>2.484858e+01</td>\n",
       "      <td>6.265499e+00</td>\n",
       "      <td>4.750840e+00</td>\n",
       "      <td>9.427730e+00</td>\n",
       "      <td>9.034381e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                dur         spkts         dpkts        sbytes        dbytes  \\\n",
       "count  8.233200e+04  8.233200e+04  8.233200e+04  8.233200e+04  8.233200e+04   \n",
       "mean   5.184270e-16 -2.096649e-15 -1.698501e-14  3.414023e-16 -1.044781e-14   \n",
       "std    1.000006e+00  1.000006e+00  1.000006e+00  1.000006e+00  1.000006e+00   \n",
       "min   -2.137298e-01 -1.319225e-01 -1.518164e-01 -4.643353e-02 -8.736871e-02   \n",
       "25%   -2.137281e-01 -1.244551e-01 -1.518164e-01 -4.590918e-02 -8.736871e-02   \n",
       "50%   -2.107283e-01 -9.458553e-02 -1.345114e-01 -4.346222e-02 -8.619357e-02   \n",
       "75%   -6.101285e-02 -4.978117e-02 -6.529130e-02 -3.911594e-02 -8.105725e-02   \n",
       "max    1.252400e+01  7.935848e+01  9.518155e+01  8.359169e+01  9.668083e+01   \n",
       "\n",
       "               rate          sttl          dttl         sload         dload  \\\n",
       "count  8.233200e+04  8.233200e+04  8.233200e+04  8.233200e+04  8.233200e+04   \n",
       "mean   2.271449e-15 -1.620620e-13  1.533671e-13 -6.077996e-15  3.152681e-14   \n",
       "std    1.000006e+00  1.000006e+00  1.000006e+00  1.000006e+00  1.000006e+00   \n",
       "min   -5.545094e-01 -1.782709e+00 -8.203947e-01 -3.588833e-01 -2.634980e-01   \n",
       "25%   -5.543169e-01 -1.171948e+00 -8.203947e-01 -3.588210e-01 -2.634980e-01   \n",
       "50%   -5.366774e-01  7.194401e-01 -5.718240e-01 -3.556752e-01 -2.626150e-01   \n",
       "75%    1.931121e-01  7.194401e-01  1.339599e+00  3.301660e-03 -2.568711e-01   \n",
       "max    6.174084e+00  7.292910e-01  1.348170e+00  2.893044e+01  8.437392e+00   \n",
       "\n",
       "       ...  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
       "count  ...      8.233200e+04      8.233200e+04    8.233200e+04  8.233200e+04   \n",
       "mean   ...     -4.653541e-14     -1.402275e-13   -3.511471e-14  5.131522e-15   \n",
       "std    ...      1.000006e+00      1.000006e+00    1.000006e+00  1.000006e+00   \n",
       "min    ...     -4.683116e-01     -4.501865e-01   -5.655971e-01 -9.085748e-02   \n",
       "25%    ...     -4.683116e-01     -4.501865e-01   -5.655971e-01 -9.085748e-02   \n",
       "50%    ...     -4.683116e-01     -4.501865e-01   -3.903909e-01 -9.085748e-02   \n",
       "75%    ...     -1.107215e-01     -1.120831e-01   -1.275816e-01 -9.085748e-02   \n",
       "max    ...      6.445097e+00      5.804726e+00    4.865795e+00  2.184603e+01   \n",
       "\n",
       "         ct_ftp_cmd  ct_flw_http_mthd    ct_src_ltm    ct_srv_dst  \\\n",
       "count  8.233200e+04      8.233200e+04  8.233200e+04  8.233200e+04   \n",
       "mean  -6.061971e-14     -2.793963e-14 -5.055105e-14 -2.861381e-14   \n",
       "std    1.000006e+00      1.000006e+00  1.000006e+00  1.000006e+00   \n",
       "min   -9.061736e-02     -2.031428e-01 -6.400328e-01 -7.341074e-01   \n",
       "25%   -9.061736e-02     -2.031428e-01 -6.400328e-01 -6.441902e-01   \n",
       "50%   -9.061736e-02     -2.031428e-01 -4.059469e-01 -3.744387e-01   \n",
       "75%   -9.061736e-02     -2.031428e-01  6.222472e-02  1.650644e-01   \n",
       "max    2.153462e+01      2.484858e+01  6.265499e+00  4.750840e+00   \n",
       "\n",
       "       is_sm_ips_ports         label  \n",
       "count     8.233200e+04  8.233200e+04  \n",
       "mean      7.580418e-14  4.793738e-15  \n",
       "std       1.000006e+00  1.000006e+00  \n",
       "min      -1.060701e-01 -1.106883e+00  \n",
       "25%      -1.060701e-01 -1.106883e+00  \n",
       "50%      -1.060701e-01  9.034381e-01  \n",
       "75%      -1.060701e-01  9.034381e-01  \n",
       "max       9.427730e+00  9.034381e-01  \n",
       "\n",
       "[8 rows x 40 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_traindf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb1f942d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>dload</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.753410e+05</td>\n",
       "      <td>1.753410e+05</td>\n",
       "      <td>1.753410e+05</td>\n",
       "      <td>1.753410e+05</td>\n",
       "      <td>1.753410e+05</td>\n",
       "      <td>1.753410e+05</td>\n",
       "      <td>1.753410e+05</td>\n",
       "      <td>1.753410e+05</td>\n",
       "      <td>1.753410e+05</td>\n",
       "      <td>1.753410e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.753410e+05</td>\n",
       "      <td>1.753410e+05</td>\n",
       "      <td>1.753410e+05</td>\n",
       "      <td>1.753410e+05</td>\n",
       "      <td>1.753410e+05</td>\n",
       "      <td>1.753410e+05</td>\n",
       "      <td>1.753410e+05</td>\n",
       "      <td>1.753410e+05</td>\n",
       "      <td>1.753410e+05</td>\n",
       "      <td>1.753410e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.812239e-15</td>\n",
       "      <td>-6.961742e-14</td>\n",
       "      <td>-1.543809e-13</td>\n",
       "      <td>3.172949e-15</td>\n",
       "      <td>5.636632e-14</td>\n",
       "      <td>-1.182600e-13</td>\n",
       "      <td>7.373804e-13</td>\n",
       "      <td>-1.607681e-13</td>\n",
       "      <td>-8.909766e-15</td>\n",
       "      <td>8.841831e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>1.736095e-13</td>\n",
       "      <td>-4.217405e-13</td>\n",
       "      <td>3.042908e-15</td>\n",
       "      <td>8.853645e-14</td>\n",
       "      <td>8.853645e-14</td>\n",
       "      <td>1.800571e-14</td>\n",
       "      <td>6.425320e-14</td>\n",
       "      <td>1.062770e-12</td>\n",
       "      <td>5.739143e-14</td>\n",
       "      <td>-3.285849e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.097747e-01</td>\n",
       "      <td>-1.409822e-01</td>\n",
       "      <td>-1.720474e-01</td>\n",
       "      <td>-5.044967e-02</td>\n",
       "      <td>-1.039229e-01</td>\n",
       "      <td>-5.768192e-01</td>\n",
       "      <td>-1.744196e+00</td>\n",
       "      <td>-7.204059e-01</td>\n",
       "      <td>-3.899726e-01</td>\n",
       "      <td>-2.772081e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.447364e-01</td>\n",
       "      <td>-5.543732e-01</td>\n",
       "      <td>-7.055286e-01</td>\n",
       "      <td>-1.185902e-01</td>\n",
       "      <td>-1.185902e-01</td>\n",
       "      <td>-1.897681e-01</td>\n",
       "      <td>-7.157137e-01</td>\n",
       "      <td>-7.530740e-01</td>\n",
       "      <td>-1.265080e-01</td>\n",
       "      <td>-1.459825e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-2.097735e-01</td>\n",
       "      <td>-1.336769e-01</td>\n",
       "      <td>-1.720474e-01</td>\n",
       "      <td>-4.995758e-02</td>\n",
       "      <td>-1.039229e-01</td>\n",
       "      <td>-5.766210e-01</td>\n",
       "      <td>-1.141901e+00</td>\n",
       "      <td>-7.204059e-01</td>\n",
       "      <td>-3.899033e-01</td>\n",
       "      <td>-2.772081e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.447364e-01</td>\n",
       "      <td>-5.543732e-01</td>\n",
       "      <td>-7.055286e-01</td>\n",
       "      <td>-1.185902e-01</td>\n",
       "      <td>-1.185902e-01</td>\n",
       "      <td>-1.897681e-01</td>\n",
       "      <td>-5.955426e-01</td>\n",
       "      <td>-6.601106e-01</td>\n",
       "      <td>-1.265080e-01</td>\n",
       "      <td>-1.459825e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.095306e-01</td>\n",
       "      <td>-1.336769e-01</td>\n",
       "      <td>-1.539081e-01</td>\n",
       "      <td>-4.814944e-02</td>\n",
       "      <td>-1.027813e-01</td>\n",
       "      <td>-5.573162e-01</td>\n",
       "      <td>7.232680e-01</td>\n",
       "      <td>-4.579780e-01</td>\n",
       "      <td>-3.853023e-01</td>\n",
       "      <td>-2.766105e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.447364e-01</td>\n",
       "      <td>-5.543732e-01</td>\n",
       "      <td>-5.229828e-01</td>\n",
       "      <td>-1.185902e-01</td>\n",
       "      <td>-1.185902e-01</td>\n",
       "      <td>-1.897681e-01</td>\n",
       "      <td>-4.753715e-01</td>\n",
       "      <td>-4.741838e-01</td>\n",
       "      <td>-1.265080e-01</td>\n",
       "      <td>6.850136e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-1.066813e-01</td>\n",
       "      <td>-6.062410e-02</td>\n",
       "      <td>-8.135096e-02</td>\n",
       "      <td>-4.249614e-02</td>\n",
       "      <td>-9.625167e-02</td>\n",
       "      <td>1.789221e-01</td>\n",
       "      <td>7.232680e-01</td>\n",
       "      <td>1.560002e+00</td>\n",
       "      <td>8.194472e-02</td>\n",
       "      <td>-2.657082e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.766180e-02</td>\n",
       "      <td>-2.085659e-01</td>\n",
       "      <td>2.984733e-01</td>\n",
       "      <td>-1.185902e-01</td>\n",
       "      <td>-1.185902e-01</td>\n",
       "      <td>-1.897681e-01</td>\n",
       "      <td>2.456551e-01</td>\n",
       "      <td>2.695234e-01</td>\n",
       "      <td>-1.265080e-01</td>\n",
       "      <td>6.850136e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.049154e+00</td>\n",
       "      <td>7.009933e+01</td>\n",
       "      <td>9.935819e+01</td>\n",
       "      <td>7.413600e+01</td>\n",
       "      <td>1.019160e+02</td>\n",
       "      <td>5.469112e+00</td>\n",
       "      <td>7.329824e-01</td>\n",
       "      <td>1.578100e+00</td>\n",
       "      <td>3.140074e+01</td>\n",
       "      <td>8.983387e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>5.668697e+00</td>\n",
       "      <td>7.226290e+00</td>\n",
       "      <td>5.135937e+00</td>\n",
       "      <td>3.161543e+01</td>\n",
       "      <td>3.161543e+01</td>\n",
       "      <td>4.259369e+01</td>\n",
       "      <td>6.374381e+00</td>\n",
       "      <td>4.917694e+00</td>\n",
       "      <td>7.904641e+00</td>\n",
       "      <td>6.850136e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                dur         spkts         dpkts        sbytes        dbytes  \\\n",
       "count  1.753410e+05  1.753410e+05  1.753410e+05  1.753410e+05  1.753410e+05   \n",
       "mean  -1.812239e-15 -6.961742e-14 -1.543809e-13  3.172949e-15  5.636632e-14   \n",
       "std    1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00   \n",
       "min   -2.097747e-01 -1.409822e-01 -1.720474e-01 -5.044967e-02 -1.039229e-01   \n",
       "25%   -2.097735e-01 -1.336769e-01 -1.720474e-01 -4.995758e-02 -1.039229e-01   \n",
       "50%   -2.095306e-01 -1.336769e-01 -1.539081e-01 -4.814944e-02 -1.027813e-01   \n",
       "75%   -1.066813e-01 -6.062410e-02 -8.135096e-02 -4.249614e-02 -9.625167e-02   \n",
       "max    9.049154e+00  7.009933e+01  9.935819e+01  7.413600e+01  1.019160e+02   \n",
       "\n",
       "               rate          sttl          dttl         sload         dload  \\\n",
       "count  1.753410e+05  1.753410e+05  1.753410e+05  1.753410e+05  1.753410e+05   \n",
       "mean  -1.182600e-13  7.373804e-13 -1.607681e-13 -8.909766e-15  8.841831e-14   \n",
       "std    1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00   \n",
       "min   -5.768192e-01 -1.744196e+00 -7.204059e-01 -3.899726e-01 -2.772081e-01   \n",
       "25%   -5.766210e-01 -1.141901e+00 -7.204059e-01 -3.899033e-01 -2.772081e-01   \n",
       "50%   -5.573162e-01  7.232680e-01 -4.579780e-01 -3.853023e-01 -2.766105e-01   \n",
       "75%    1.789221e-01  7.232680e-01  1.560002e+00  8.194472e-02 -2.657082e-01   \n",
       "max    5.469112e+00  7.329824e-01  1.578100e+00  3.140074e+01  8.983387e+00   \n",
       "\n",
       "       ...  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
       "count  ...      1.753410e+05      1.753410e+05    1.753410e+05  1.753410e+05   \n",
       "mean   ...      1.736095e-13     -4.217405e-13    3.042908e-15  8.853645e-14   \n",
       "std    ...      1.000003e+00      1.000003e+00    1.000003e+00  1.000003e+00   \n",
       "min    ...     -5.447364e-01     -5.543732e-01   -7.055286e-01 -1.185902e-01   \n",
       "25%    ...     -5.447364e-01     -5.543732e-01   -7.055286e-01 -1.185902e-01   \n",
       "50%    ...     -5.447364e-01     -5.543732e-01   -5.229828e-01 -1.185902e-01   \n",
       "75%    ...     -4.766180e-02     -2.085659e-01    2.984733e-01 -1.185902e-01   \n",
       "max    ...      5.668697e+00      7.226290e+00    5.135937e+00  3.161543e+01   \n",
       "\n",
       "         ct_ftp_cmd  ct_flw_http_mthd    ct_src_ltm    ct_srv_dst  \\\n",
       "count  1.753410e+05      1.753410e+05  1.753410e+05  1.753410e+05   \n",
       "mean   8.853645e-14      1.800571e-14  6.425320e-14  1.062770e-12   \n",
       "std    1.000003e+00      1.000003e+00  1.000003e+00  1.000003e+00   \n",
       "min   -1.185902e-01     -1.897681e-01 -7.157137e-01 -7.530740e-01   \n",
       "25%   -1.185902e-01     -1.897681e-01 -5.955426e-01 -6.601106e-01   \n",
       "50%   -1.185902e-01     -1.897681e-01 -4.753715e-01 -4.741838e-01   \n",
       "75%   -1.185902e-01     -1.897681e-01  2.456551e-01  2.695234e-01   \n",
       "max    3.161543e+01      4.259369e+01  6.374381e+00  4.917694e+00   \n",
       "\n",
       "       is_sm_ips_ports         label  \n",
       "count     1.753410e+05  1.753410e+05  \n",
       "mean      5.739143e-14 -3.285849e-13  \n",
       "std       1.000003e+00  1.000003e+00  \n",
       "min      -1.265080e-01 -1.459825e+00  \n",
       "25%      -1.265080e-01 -1.459825e+00  \n",
       "50%      -1.265080e-01  6.850136e-01  \n",
       "75%      -1.265080e-01  6.850136e-01  \n",
       "max       7.904641e+00  6.850136e-01  \n",
       "\n",
       "[8 rows x 40 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_testdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c194129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LE = LabelEncoder()\n",
    "\n",
    "# extract categorical attributes from both training and test sets\n",
    "obj_train = train.select_dtypes(include=['object']).copy()\n",
    "obj_test = test.select_dtypes(include=['object']).copy()\n",
    "#print(obj_train)\n",
    "#print(obj_pred)\n",
    "\n",
    "# encode the categorical attributes\n",
    "LE_obj_train = obj_train.apply(LE.fit_transform)\n",
    "LE_obj_test = obj_test.apply(LE.fit_transform)\n",
    "\n",
    "# separate target column from encoded data \n",
    "enctrain = LE_obj_train.drop(['attack_cat'], axis=1)\n",
    "#print(enctrain)\n",
    "enctest = LE_obj_test.drop(['attack_cat'],axis=1)\n",
    "#print(encpred)\n",
    "test_target = test['attack_cat']\n",
    "#lir_tar_train = LE_obj_train['attack_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37dbaa99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82332, 43)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = pd.concat([sc_traindf,enctrain],axis=1)\n",
    "train_y = train['attack_cat']\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e6ec215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175341, 43)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.concat([sc_testdf,enctest],axis=1)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3da18014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 792x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier();\n",
    "\n",
    "# fit random forest classifier on the training set\n",
    "rfc.fit(train_x, train_y);\n",
    "\n",
    "# extract important features\n",
    "score = np.round(rfc.feature_importances_,3)\n",
    "importances = pd.DataFrame({'feature':train_x.columns,'importance':score})\n",
    "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
    "\n",
    "# plot importances\n",
    "plt.rcParams['figure.figsize'] = (11, 4)\n",
    "importances.plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f60abe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dur',\n",
       " 'sbytes',\n",
       " 'dbytes',\n",
       " 'rate',\n",
       " 'sttl',\n",
       " 'sload',\n",
       " 'dload',\n",
       " 'smean',\n",
       " 'dmean',\n",
       " 'ct_srv_src',\n",
       " 'ct_dst_sport_ltm',\n",
       " 'ct_dst_src_ltm',\n",
       " 'ct_srv_dst',\n",
       " 'label',\n",
       " 'service']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "import itertools\n",
    "#rfc = RandomForestClassifier()\n",
    "\n",
    "# create the RFE model and select 10 attributes\n",
    "rfe = RFE(rfc, n_features_to_select=15)\n",
    "rfe = rfe.fit(train_x, train_y)\n",
    "\n",
    "# summarize the selection of the attributes\n",
    "feature_map = [(i, v) for i, v in itertools.zip_longest(rfe.get_support(), train_x.columns)]\n",
    "selected_features = [v for i, v in feature_map if i==True]\n",
    "\n",
    "selected_train = train_x.loc[:, selected_features]\n",
    "#print()\n",
    "selected_test = test_df.loc[:, selected_features]\n",
    "\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fafeffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(selected_train,train_y,train_size=0.70, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51113c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training different Machine Learning models for comapritive analysis\n",
    "DTC_Classifier = tree.DecisionTreeClassifier(criterion='entropy', random_state=0) #Decision Tree Classifier\n",
    "\n",
    "LGR_Classifier = LogisticRegression(n_jobs=-1, random_state=0) #Logistic Regression\n",
    "\n",
    "BNB_Classifier = BernoulliNB() #Naive Bayes Algorithm\n",
    "\n",
    "#LIR_Classifier = LinearRegression() #Multi Linear Regression\n",
    "gradient_booster = GradientBoostingClassifier(learning_rate=0.1)\n",
    "\n",
    "SVM_Classifier = SVC(kernel = 'poly',C = 75) #Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "541acfc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=75, kernel='poly')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTC_Classifier.fit(X_train, Y_train)\n",
    "\n",
    "LGR_Classifier.fit(X_train, Y_train)\n",
    "\n",
    "BNB_Classifier.fit(X_train, Y_train)\n",
    "\n",
    "#LIR_Classifier.fit(mlrx_train, mlry_train)\n",
    "\n",
    "gradient_booster.fit(X_train,Y_train)\n",
    "\n",
    "SVM_Classifier.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f2726ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('Decision Tree Classifier', DTC_Classifier))\n",
    "models.append(('Logistic Regression', LGR_Classifier))\n",
    "models.append(('Naive Baye Classifier', BNB_Classifier))\n",
    "models.append(('Gradient Booster Classifier', gradient_booster))\n",
    "models.append(('Support Vector Machine', SVM_Classifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df608331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== Decision Tree Classifier Model Evaluation ==============================\n",
      "Model Accuracy:\n",
      " 0.9387666574125486\n",
      "\n",
      "Confusion matrix:\n",
      " [[   62     3    75   232   100     0     0     0     0     0]\n",
      " [   17    55    23   222    92     0     0     0     0     0]\n",
      " [   12    11  2126   580    99     0     0     2     0     0]\n",
      " [   19    16   981  6645   156     1     0     0     0     0]\n",
      " [   18    14   152   435  3611     0     0     2     0     0]\n",
      " [    0     0    20     9     0 13182     0     0     0     0]\n",
      " [    0     0     0     0     0     0 25902     0     0     0]\n",
      " [    0     1   143    93     0     0     0  2224     0     0]\n",
      " [    0     0     0     0     0     0     0     0   268     0]\n",
      " [    0     0     1     0     0     0     0     0     0    28]]\n",
      "\n",
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.48      0.13      0.21       472\n",
      "      Backdoor       0.55      0.13      0.22       409\n",
      "           DoS       0.60      0.75      0.67      2830\n",
      "      Exploits       0.81      0.85      0.83      7818\n",
      "       Fuzzers       0.89      0.85      0.87      4232\n",
      "       Generic       1.00      1.00      1.00     13211\n",
      "        Normal       1.00      1.00      1.00     25902\n",
      "Reconnaissance       1.00      0.90      0.95      2461\n",
      "     Shellcode       1.00      1.00      1.00       268\n",
      "         Worms       1.00      0.97      0.98        29\n",
      "\n",
      "      accuracy                           0.94     57632\n",
      "     macro avg       0.83      0.76      0.77     57632\n",
      "  weighted avg       0.94      0.94      0.94     57632\n",
      "\n",
      "\n",
      "\n",
      "============================== Logistic Regression Model Evaluation ==============================\n",
      "Model Accuracy:\n",
      " 0.8519398945030539\n",
      "\n",
      "Confusion matrix:\n",
      " [[    7     0    27   143   157   125     0    13     0     0]\n",
      " [    4     0    11    64   160   131     0    39     0     0]\n",
      " [    4     0   249  1656   385   227     0   309     0     0]\n",
      " [   12     0   228  5524  1052   432     0   570     0     0]\n",
      " [    9     0    52   473  2900   415     0   383     0     0]\n",
      " [    0     0     2   324   143 12666     0    76     0     0]\n",
      " [    0     0     0     0     0     0 25902     0     0     0]\n",
      " [    0     0    40   329   191    50     0  1851     0     0]\n",
      " [    0     0     1    37    34     0     0   196     0     0]\n",
      " [    0     0     0    19     3     6     0     1     0     0]]\n",
      "\n",
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.19      0.01      0.03       472\n",
      "      Backdoor       0.00      0.00      0.00       409\n",
      "           DoS       0.41      0.09      0.14      2830\n",
      "      Exploits       0.64      0.71      0.67      7818\n",
      "       Fuzzers       0.58      0.69      0.63      4232\n",
      "       Generic       0.90      0.96      0.93     13211\n",
      "        Normal       1.00      1.00      1.00     25902\n",
      "Reconnaissance       0.54      0.75      0.63      2461\n",
      "     Shellcode       0.00      0.00      0.00       268\n",
      "         Worms       0.00      0.00      0.00        29\n",
      "\n",
      "      accuracy                           0.85     57632\n",
      "     macro avg       0.43      0.42      0.40     57632\n",
      "  weighted avg       0.83      0.85      0.83     57632\n",
      "\n",
      "\n",
      "\n",
      "============================== Naive Baye Classifier Model Evaluation ==============================\n",
      "Model Accuracy:\n",
      " 0.8065484453081622\n",
      "\n",
      "Confusion matrix:\n",
      " [[   68   174   145    41    17    27     0     0     0     0]\n",
      " [   67   164    77    20    28    26     0    27     0     0]\n",
      " [   61   170  1447   738   224    68     0   122     0     0]\n",
      " [  136   349  1382  4927   556    97     0   371     0     0]\n",
      " [  158   333   599   465  1497    91     0  1089     0     0]\n",
      " [    0     0   593   347    67 11599     0   605     0     0]\n",
      " [    0     0     0     0     0     0 25902     0     0     0]\n",
      " [    2     0   838   355   379     8     0   879     0     0]\n",
      " [    0     0   102     0    29     0     0   137     0     0]\n",
      " [    0     0     4    23     0     0     0     2     0     0]]\n",
      "\n",
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.14      0.14      0.14       472\n",
      "      Backdoor       0.14      0.40      0.21       409\n",
      "           DoS       0.28      0.51      0.36      2830\n",
      "      Exploits       0.71      0.63      0.67      7818\n",
      "       Fuzzers       0.54      0.35      0.43      4232\n",
      "       Generic       0.97      0.88      0.92     13211\n",
      "        Normal       1.00      1.00      1.00     25902\n",
      "Reconnaissance       0.27      0.36      0.31      2461\n",
      "     Shellcode       0.00      0.00      0.00       268\n",
      "         Worms       0.00      0.00      0.00        29\n",
      "\n",
      "      accuracy                           0.81     57632\n",
      "     macro avg       0.40      0.43      0.40     57632\n",
      "  weighted avg       0.84      0.81      0.82     57632\n",
      "\n",
      "\n",
      "\n",
      "============================== Gradient Booster Classifier Model Evaluation ==============================\n",
      "Model Accuracy:\n",
      " 0.9033523042754026\n",
      "\n",
      "Confusion matrix:\n",
      " [[   37     0   105   250    80     0     0     0     0     0]\n",
      " [    0    18    32   268    86     0     0     1     4     0]\n",
      " [    1     0  1521  1074   152    19     0    30    32     1]\n",
      " [    1     0  1239  6058   353    24     0   112    31     0]\n",
      " [    0     0   209   581  3422     2     0    11     7     0]\n",
      " [    0     0    25   254    46 12879     0     0     6     1]\n",
      " [    0     0     0     0     0     0 25902     0     0     0]\n",
      " [    0     0   173   234    34     0     0  2016     4     0]\n",
      " [    0     0     2    40    26     3     0    17   180     0]\n",
      " [    0     0     0     0     0     0     0     0     0    29]]\n",
      "\n",
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.95      0.08      0.14       472\n",
      "      Backdoor       1.00      0.04      0.08       409\n",
      "           DoS       0.46      0.54      0.50      2830\n",
      "      Exploits       0.69      0.77      0.73      7818\n",
      "       Fuzzers       0.81      0.81      0.81      4232\n",
      "       Generic       1.00      0.97      0.99     13211\n",
      "        Normal       1.00      1.00      1.00     25902\n",
      "Reconnaissance       0.92      0.82      0.87      2461\n",
      "     Shellcode       0.68      0.67      0.68       268\n",
      "         Worms       0.94      1.00      0.97        29\n",
      "\n",
      "      accuracy                           0.90     57632\n",
      "     macro avg       0.85      0.67      0.68     57632\n",
      "  weighted avg       0.91      0.90      0.90     57632\n",
      "\n",
      "\n",
      "\n",
      "============================== Support Vector Machine Model Evaluation ==============================\n",
      "Model Accuracy:\n",
      " 0.8837798445308163\n",
      "\n",
      "Confusion matrix:\n",
      " [[    1     0    62   246   162     0     0     1     0     0]\n",
      " [    0     0    14   188   177     0     0    30     0     0]\n",
      " [    1     0   913  1448   274    27     0   167     0     0]\n",
      " [    0     1   693  6109   667    29     0   315     4     0]\n",
      " [    0     0   118   588  3334     5     0   185     2     0]\n",
      " [    0     0    37   277    48 12815     0    32     1     1]\n",
      " [    0     0     0     0     0     0 25902     0     0     0]\n",
      " [    0     0   114   321   175     4     0  1847     0     0]\n",
      " [    0     0     8    62    22     3     0   163    10     0]\n",
      " [    0     0     0    24     1     0     0     1     0     3]]\n",
      "\n",
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.50      0.00      0.00       472\n",
      "      Backdoor       0.00      0.00      0.00       409\n",
      "           DoS       0.47      0.32      0.38      2830\n",
      "      Exploits       0.66      0.78      0.72      7818\n",
      "       Fuzzers       0.69      0.79      0.73      4232\n",
      "       Generic       0.99      0.97      0.98     13211\n",
      "        Normal       1.00      1.00      1.00     25902\n",
      "Reconnaissance       0.67      0.75      0.71      2461\n",
      "     Shellcode       0.59      0.04      0.07       268\n",
      "         Worms       0.75      0.10      0.18        29\n",
      "\n",
      "      accuracy                           0.88     57632\n",
      "     macro avg       0.63      0.48      0.48     57632\n",
      "  weighted avg       0.88      0.88      0.87     57632\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, v in models:\n",
    "    accuracy = metrics.accuracy_score(Y_train, v.predict(X_train))\n",
    "    confusion_matrix = metrics.confusion_matrix(Y_train, v.predict(X_train))\n",
    "    classification = metrics.classification_report(Y_train, v.predict(X_train))\n",
    "    print()\n",
    "    print('============================== {} Model Evaluation =============================='.format(i))\n",
    "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
    "    print()\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
    "    print()\n",
    "    print(\"Classification report:\" \"\\n\", classification) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07709301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== Decision Tree Classifier Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.887004048582996\n",
      "\n",
      "Confusion matrix:\n",
      " [[   15     9    42   104    35     0     0     0     0     0]\n",
      " [    4     5    15   101    46     2     0     1     0     0]\n",
      " [   11     4   646   505    59    20     0     5     8     1]\n",
      " [   28    15   655  2309   156    54     0    74    18     5]\n",
      " [   24    16    85   281  1400    10     0     6     8     0]\n",
      " [    0     4    27    63    22  5536     0     3     5     0]\n",
      " [    0     0     0     0     0     0 11098     0     0     0]\n",
      " [    0     2    78   105     6     2     0   837     5     0]\n",
      " [    0     1    14    20    11     3     0     1    60     0]\n",
      " [    0     0     4     4     2     2     0     0     0     3]]\n",
      "\n",
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.18      0.07      0.10       205\n",
      "      Backdoor       0.09      0.03      0.04       174\n",
      "           DoS       0.41      0.51      0.46      1259\n",
      "      Exploits       0.66      0.70      0.68      3314\n",
      "       Fuzzers       0.81      0.77      0.78      1830\n",
      "       Generic       0.98      0.98      0.98      5660\n",
      "        Normal       1.00      1.00      1.00     11098\n",
      "Reconnaissance       0.90      0.81      0.85      1035\n",
      "     Shellcode       0.58      0.55      0.56       110\n",
      "         Worms       0.33      0.20      0.25        15\n",
      "\n",
      "      accuracy                           0.89     24700\n",
      "     macro avg       0.59      0.56      0.57     24700\n",
      "  weighted avg       0.89      0.89      0.89     24700\n",
      "\n",
      "\n",
      "\n",
      "============================== Logistic Regression Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.8521052631578947\n",
      "\n",
      "Confusion matrix:\n",
      " [[    0     0    13    66    58    63     0     5     0     0]\n",
      " [    3     0     6    22    70    58     0    15     0     0]\n",
      " [    4     0   103   734   175   105     0   138     0     0]\n",
      " [    4     0    92  2406   411   156     0   245     0     0]\n",
      " [    5     0    20   215  1250   184     0   156     0     0]\n",
      " [    0     0     0   151    55  5413     0    41     0     0]\n",
      " [    0     0     0     0     0     0 11098     0     0     0]\n",
      " [    0     0    14   148    68    28     0   777     0     0]\n",
      " [    0     0     0    12    28     0     0    70     0     0]\n",
      " [    0     0     0     6     3     5     0     1     0     0]]\n",
      "\n",
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.00      0.00      0.00       205\n",
      "      Backdoor       0.00      0.00      0.00       174\n",
      "           DoS       0.42      0.08      0.14      1259\n",
      "      Exploits       0.64      0.73      0.68      3314\n",
      "       Fuzzers       0.59      0.68      0.63      1830\n",
      "       Generic       0.90      0.96      0.93      5660\n",
      "        Normal       1.00      1.00      1.00     11098\n",
      "Reconnaissance       0.54      0.75      0.63      1035\n",
      "     Shellcode       0.00      0.00      0.00       110\n",
      "         Worms       0.00      0.00      0.00        15\n",
      "\n",
      "      accuracy                           0.85     24700\n",
      "     macro avg       0.41      0.42      0.40     24700\n",
      "  weighted avg       0.83      0.85      0.83     24700\n",
      "\n",
      "\n",
      "\n",
      "============================== Naive Baye Classifier Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.8051821862348179\n",
      "\n",
      "Confusion matrix:\n",
      " [[   22    67    76    17     9    12     0     2     0     0]\n",
      " [   23    77    28    13     9    13     0    11     0     0]\n",
      " [   29    71   655   314    93    34     0    63     0     0]\n",
      " [   44   133   599  2118   225    26     0   169     0     0]\n",
      " [   86   149   282   202   626    26     0   459     0     0]\n",
      " [    0     0   259   141    28  4962     0   270     0     0]\n",
      " [    2     0     0     0     0     0 11096     0     0     0]\n",
      " [    0     0   391   152   156     4     0   332     0     0]\n",
      " [    0     0    49     0    14     0     0    47     0     0]\n",
      " [    0     0     2    11     0     0     0     2     0     0]]\n",
      "\n",
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.11      0.11      0.11       205\n",
      "      Backdoor       0.15      0.44      0.23       174\n",
      "           DoS       0.28      0.52      0.36      1259\n",
      "      Exploits       0.71      0.64      0.67      3314\n",
      "       Fuzzers       0.54      0.34      0.42      1830\n",
      "       Generic       0.98      0.88      0.92      5660\n",
      "        Normal       1.00      1.00      1.00     11098\n",
      "Reconnaissance       0.25      0.32      0.28      1035\n",
      "     Shellcode       0.00      0.00      0.00       110\n",
      "         Worms       0.00      0.00      0.00        15\n",
      "\n",
      "      accuracy                           0.81     24700\n",
      "     macro avg       0.40      0.42      0.40     24700\n",
      "  weighted avg       0.84      0.81      0.82     24700\n",
      "\n",
      "\n",
      "\n",
      "============================== Gradient Booster Classifier Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.8981781376518219\n",
      "\n",
      "Confusion matrix:\n",
      " [[   17     0    58    95    35     0     0     0     0     0]\n",
      " [    0     5    18   109    41     0     0     1     0     0]\n",
      " [    0     0   666   487    72     7     0    14    11     2]\n",
      " [    1     0   559  2542   134    13     0    53    10     2]\n",
      " [    0     0    98   248  1474     0     0     3     7     0]\n",
      " [    2     0     6   142    22  5480     0     2     5     1]\n",
      " [    0     0     0     0     0     0 11096     0     2     0]\n",
      " [    0     0    77   103    15     0     0   838     2     0]\n",
      " [    0     0     0    20    20     1     0    11    58     0]\n",
      " [    0     0     0     6     0     0     0     0     0     9]]\n",
      "\n",
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.85      0.08      0.15       205\n",
      "      Backdoor       1.00      0.03      0.06       174\n",
      "           DoS       0.45      0.53      0.49      1259\n",
      "      Exploits       0.68      0.77      0.72      3314\n",
      "       Fuzzers       0.81      0.81      0.81      1830\n",
      "       Generic       1.00      0.97      0.98      5660\n",
      "        Normal       1.00      1.00      1.00     11098\n",
      "Reconnaissance       0.91      0.81      0.86      1035\n",
      "     Shellcode       0.61      0.53      0.57       110\n",
      "         Worms       0.64      0.60      0.62        15\n",
      "\n",
      "      accuracy                           0.90     24700\n",
      "     macro avg       0.79      0.61      0.62     24700\n",
      "  weighted avg       0.91      0.90      0.90     24700\n",
      "\n",
      "\n",
      "\n",
      "============================== Support Vector Machine Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.8806882591093117\n",
      "\n",
      "Confusion matrix:\n",
      " [[    0     0    32    97    74     0     0     2     0     0]\n",
      " [    0     0    11    77    73     1     0    12     0     0]\n",
      " [    0     0   346   697   119    15     0    81     1     0]\n",
      " [    1     0   301  2616   244    11     0   141     0     0]\n",
      " [    0     0    65   261  1426     3     0    74     1     0]\n",
      " [    0     0    11   128    32  5475     0    14     0     0]\n",
      " [    0     0     0     0     0     0 11098     0     0     0]\n",
      " [    0     0    48   135    69     2     0   781     0     0]\n",
      " [    0     0     2    31    13     1     0    56     7     0]\n",
      " [    0     0     0     9     2     0     0     0     0     4]]\n",
      "\n",
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.00      0.00      0.00       205\n",
      "      Backdoor       0.00      0.00      0.00       174\n",
      "           DoS       0.42      0.27      0.33      1259\n",
      "      Exploits       0.65      0.79      0.71      3314\n",
      "       Fuzzers       0.69      0.78      0.73      1830\n",
      "       Generic       0.99      0.97      0.98      5660\n",
      "        Normal       1.00      1.00      1.00     11098\n",
      "Reconnaissance       0.67      0.75      0.71      1035\n",
      "     Shellcode       0.78      0.06      0.12       110\n",
      "         Worms       1.00      0.27      0.42        15\n",
      "\n",
      "      accuracy                           0.88     24700\n",
      "     macro avg       0.62      0.49      0.50     24700\n",
      "  weighted avg       0.87      0.88      0.87     24700\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, v in models:\n",
    "    accuracy = metrics.accuracy_score(Y_test, v.predict(X_test))\n",
    "    confusion_matrix = metrics.confusion_matrix(Y_test, v.predict(X_test))\n",
    "    classification = metrics.classification_report(Y_test, v.predict(X_test))\n",
    "    print()\n",
    "    print('============================== {} Model Test Results =============================='.format(i))\n",
    "    print()\n",
    "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
    "    print()\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
    "    print()\n",
    "    print(\"Classification report:\" \"\\n\", classification) \n",
    "    print()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89d5b9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 'single' for predicting single value\n",
      "Enter 'range' to predict a range of values : range\n",
      "\n",
      "Enter the range for prediction between [0,175340]: 50000 50020\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>dload</th>\n",
       "      <th>smean</th>\n",
       "      <th>dmean</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>label</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>0.661855</td>\n",
       "      <td>0.035162</td>\n",
       "      <td>-0.103923</td>\n",
       "      <td>-0.576696</td>\n",
       "      <td>0.723268</td>\n",
       "      <td>-0.389861</td>\n",
       "      <td>-0.277208</td>\n",
       "      <td>-0.037873</td>\n",
       "      <td>-0.480703</td>\n",
       "      <td>-0.682570</td>\n",
       "      <td>-0.381470</td>\n",
       "      <td>-0.614256</td>\n",
       "      <td>-0.660111</td>\n",
       "      <td>0.685014</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50001</th>\n",
       "      <td>-0.209774</td>\n",
       "      <td>-0.049465</td>\n",
       "      <td>-0.103923</td>\n",
       "      <td>0.632367</td>\n",
       "      <td>0.723268</td>\n",
       "      <td>0.459479</td>\n",
       "      <td>-0.277208</td>\n",
       "      <td>-0.179560</td>\n",
       "      <td>-0.480703</td>\n",
       "      <td>-0.589150</td>\n",
       "      <td>-0.381470</td>\n",
       "      <td>-0.522983</td>\n",
       "      <td>-0.567147</td>\n",
       "      <td>0.685014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50002</th>\n",
       "      <td>-0.209774</td>\n",
       "      <td>-0.045208</td>\n",
       "      <td>-0.103923</td>\n",
       "      <td>2.446146</td>\n",
       "      <td>0.723268</td>\n",
       "      <td>9.633551</td>\n",
       "      <td>-0.277208</td>\n",
       "      <td>1.637940</td>\n",
       "      <td>-0.480703</td>\n",
       "      <td>-0.775991</td>\n",
       "      <td>-0.554373</td>\n",
       "      <td>-0.614256</td>\n",
       "      <td>-0.753074</td>\n",
       "      <td>0.685014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50003</th>\n",
       "      <td>-0.209773</td>\n",
       "      <td>-0.049465</td>\n",
       "      <td>-0.103923</td>\n",
       "      <td>0.094951</td>\n",
       "      <td>0.723268</td>\n",
       "      <td>0.081945</td>\n",
       "      <td>-0.277208</td>\n",
       "      <td>-0.179560</td>\n",
       "      <td>-0.480703</td>\n",
       "      <td>-0.495729</td>\n",
       "      <td>-0.381470</td>\n",
       "      <td>-0.431710</td>\n",
       "      <td>-0.474184</td>\n",
       "      <td>0.685014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50004</th>\n",
       "      <td>-0.181591</td>\n",
       "      <td>-0.048539</td>\n",
       "      <td>-0.102684</td>\n",
       "      <td>-0.576455</td>\n",
       "      <td>0.723268</td>\n",
       "      <td>-0.389899</td>\n",
       "      <td>-0.274784</td>\n",
       "      <td>-0.448276</td>\n",
       "      <td>-0.306498</td>\n",
       "      <td>0.064793</td>\n",
       "      <td>-0.554373</td>\n",
       "      <td>-0.705529</td>\n",
       "      <td>-0.753074</td>\n",
       "      <td>0.685014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50005</th>\n",
       "      <td>-0.209773</td>\n",
       "      <td>-0.049465</td>\n",
       "      <td>-0.103923</td>\n",
       "      <td>0.094951</td>\n",
       "      <td>0.723268</td>\n",
       "      <td>0.081945</td>\n",
       "      <td>-0.277208</td>\n",
       "      <td>-0.179560</td>\n",
       "      <td>-0.480703</td>\n",
       "      <td>-0.495729</td>\n",
       "      <td>-0.381470</td>\n",
       "      <td>-0.431710</td>\n",
       "      <td>-0.474184</td>\n",
       "      <td>0.685014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50006</th>\n",
       "      <td>-0.170780</td>\n",
       "      <td>-0.043606</td>\n",
       "      <td>-0.102057</td>\n",
       "      <td>-0.576460</td>\n",
       "      <td>0.723268</td>\n",
       "      <td>-0.389787</td>\n",
       "      <td>-0.274279</td>\n",
       "      <td>-0.072073</td>\n",
       "      <td>-0.306498</td>\n",
       "      <td>-0.775991</td>\n",
       "      <td>-0.554373</td>\n",
       "      <td>-0.614256</td>\n",
       "      <td>-0.753074</td>\n",
       "      <td>0.685014</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50007</th>\n",
       "      <td>-0.209773</td>\n",
       "      <td>-0.049465</td>\n",
       "      <td>-0.103923</td>\n",
       "      <td>0.094951</td>\n",
       "      <td>0.723268</td>\n",
       "      <td>0.081945</td>\n",
       "      <td>-0.277208</td>\n",
       "      <td>-0.179560</td>\n",
       "      <td>-0.480703</td>\n",
       "      <td>-0.495729</td>\n",
       "      <td>-0.381470</td>\n",
       "      <td>-0.431710</td>\n",
       "      <td>-0.474184</td>\n",
       "      <td>0.685014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50008</th>\n",
       "      <td>-0.070533</td>\n",
       "      <td>-0.047383</td>\n",
       "      <td>-0.101459</td>\n",
       "      <td>-0.576705</td>\n",
       "      <td>0.723268</td>\n",
       "      <td>-0.389949</td>\n",
       "      <td>-0.276073</td>\n",
       "      <td>-0.394533</td>\n",
       "      <td>-0.310369</td>\n",
       "      <td>-0.775991</td>\n",
       "      <td>-0.554373</td>\n",
       "      <td>-0.705529</td>\n",
       "      <td>-0.753074</td>\n",
       "      <td>0.685014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50009</th>\n",
       "      <td>-0.209773</td>\n",
       "      <td>-0.049465</td>\n",
       "      <td>-0.103923</td>\n",
       "      <td>0.094951</td>\n",
       "      <td>0.723268</td>\n",
       "      <td>0.081945</td>\n",
       "      <td>-0.277208</td>\n",
       "      <td>-0.179560</td>\n",
       "      <td>-0.480703</td>\n",
       "      <td>-0.495729</td>\n",
       "      <td>-0.381470</td>\n",
       "      <td>-0.431710</td>\n",
       "      <td>-0.474184</td>\n",
       "      <td>0.685014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50010</th>\n",
       "      <td>-0.131619</td>\n",
       "      <td>-0.040150</td>\n",
       "      <td>-0.090947</td>\n",
       "      <td>-0.576569</td>\n",
       "      <td>0.723268</td>\n",
       "      <td>-0.389832</td>\n",
       "      <td>-0.266261</td>\n",
       "      <td>0.074499</td>\n",
       "      <td>0.239345</td>\n",
       "      <td>-0.775991</td>\n",
       "      <td>-0.554373</td>\n",
       "      <td>-0.705529</td>\n",
       "      <td>-0.195294</td>\n",
       "      <td>0.685014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50011</th>\n",
       "      <td>-0.209773</td>\n",
       "      <td>-0.049465</td>\n",
       "      <td>-0.103923</td>\n",
       "      <td>0.094951</td>\n",
       "      <td>0.723268</td>\n",
       "      <td>0.081945</td>\n",
       "      <td>-0.277208</td>\n",
       "      <td>-0.179560</td>\n",
       "      <td>-0.480703</td>\n",
       "      <td>-0.495729</td>\n",
       "      <td>-0.381470</td>\n",
       "      <td>-0.431710</td>\n",
       "      <td>-0.474184</td>\n",
       "      <td>0.685014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50012</th>\n",
       "      <td>-0.077206</td>\n",
       "      <td>-0.045460</td>\n",
       "      <td>-0.099454</td>\n",
       "      <td>-0.576629</td>\n",
       "      <td>0.723268</td>\n",
       "      <td>-0.389931</td>\n",
       "      <td>-0.274943</td>\n",
       "      <td>-0.394533</td>\n",
       "      <td>-0.271657</td>\n",
       "      <td>-0.308889</td>\n",
       "      <td>-0.208566</td>\n",
       "      <td>-0.249164</td>\n",
       "      <td>-0.195294</td>\n",
       "      <td>0.685014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50013</th>\n",
       "      <td>-0.171849</td>\n",
       "      <td>-0.041409</td>\n",
       "      <td>-0.098702</td>\n",
       "      <td>-0.576352</td>\n",
       "      <td>0.723268</td>\n",
       "      <td>-0.389718</td>\n",
       "      <td>-0.268376</td>\n",
       "      <td>-0.013444</td>\n",
       "      <td>-0.116808</td>\n",
       "      <td>0.345054</td>\n",
       "      <td>-0.554373</td>\n",
       "      <td>0.207200</td>\n",
       "      <td>0.176560</td>\n",
       "      <td>0.685014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50014</th>\n",
       "      <td>-0.136713</td>\n",
       "      <td>-0.045884</td>\n",
       "      <td>-0.094442</td>\n",
       "      <td>-0.576602</td>\n",
       "      <td>-1.141901</td>\n",
       "      <td>-0.389906</td>\n",
       "      <td>-0.268890</td>\n",
       "      <td>-0.262618</td>\n",
       "      <td>0.177405</td>\n",
       "      <td>-0.775991</td>\n",
       "      <td>-0.554373</td>\n",
       "      <td>-0.705529</td>\n",
       "      <td>-0.753074</td>\n",
       "      <td>0.685014</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50015</th>\n",
       "      <td>-0.209774</td>\n",
       "      <td>-0.049465</td>\n",
       "      <td>-0.103923</td>\n",
       "      <td>0.178922</td>\n",
       "      <td>0.723268</td>\n",
       "      <td>0.140934</td>\n",
       "      <td>-0.277208</td>\n",
       "      <td>-0.179560</td>\n",
       "      <td>-0.480703</td>\n",
       "      <td>-0.495729</td>\n",
       "      <td>-0.381470</td>\n",
       "      <td>-0.431710</td>\n",
       "      <td>-0.474184</td>\n",
       "      <td>0.685014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50016</th>\n",
       "      <td>-0.121280</td>\n",
       "      <td>-0.042839</td>\n",
       "      <td>-0.098215</td>\n",
       "      <td>-0.576598</td>\n",
       "      <td>0.723268</td>\n",
       "      <td>-0.389880</td>\n",
       "      <td>-0.272956</td>\n",
       "      <td>-0.116045</td>\n",
       "      <td>-0.163263</td>\n",
       "      <td>-0.308889</td>\n",
       "      <td>-0.554373</td>\n",
       "      <td>-0.249164</td>\n",
       "      <td>-0.288257</td>\n",
       "      <td>0.685014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50017</th>\n",
       "      <td>0.021835</td>\n",
       "      <td>-0.045060</td>\n",
       "      <td>-0.093063</td>\n",
       "      <td>-0.576743</td>\n",
       "      <td>-1.141901</td>\n",
       "      <td>-0.389948</td>\n",
       "      <td>-0.274117</td>\n",
       "      <td>-0.194217</td>\n",
       "      <td>0.123208</td>\n",
       "      <td>-0.682570</td>\n",
       "      <td>-0.554373</td>\n",
       "      <td>-0.614256</td>\n",
       "      <td>-0.660111</td>\n",
       "      <td>0.685014</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50018</th>\n",
       "      <td>-0.209774</td>\n",
       "      <td>-0.049465</td>\n",
       "      <td>-0.103923</td>\n",
       "      <td>0.178922</td>\n",
       "      <td>0.723268</td>\n",
       "      <td>0.140934</td>\n",
       "      <td>-0.277208</td>\n",
       "      <td>-0.179560</td>\n",
       "      <td>-0.480703</td>\n",
       "      <td>-0.495729</td>\n",
       "      <td>-0.381470</td>\n",
       "      <td>-0.431710</td>\n",
       "      <td>-0.474184</td>\n",
       "      <td>0.685014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50019</th>\n",
       "      <td>-0.140907</td>\n",
       "      <td>-0.042862</td>\n",
       "      <td>-0.099106</td>\n",
       "      <td>-0.576562</td>\n",
       "      <td>0.723268</td>\n",
       "      <td>-0.389854</td>\n",
       "      <td>-0.272722</td>\n",
       "      <td>-0.116045</td>\n",
       "      <td>-0.143906</td>\n",
       "      <td>-0.308889</td>\n",
       "      <td>-0.554373</td>\n",
       "      <td>-0.249164</td>\n",
       "      <td>-0.288257</td>\n",
       "      <td>0.685014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dur    sbytes    dbytes      rate      sttl     sload     dload  \\\n",
       "50000  0.661855  0.035162 -0.103923 -0.576696  0.723268 -0.389861 -0.277208   \n",
       "50001 -0.209774 -0.049465 -0.103923  0.632367  0.723268  0.459479 -0.277208   \n",
       "50002 -0.209774 -0.045208 -0.103923  2.446146  0.723268  9.633551 -0.277208   \n",
       "50003 -0.209773 -0.049465 -0.103923  0.094951  0.723268  0.081945 -0.277208   \n",
       "50004 -0.181591 -0.048539 -0.102684 -0.576455  0.723268 -0.389899 -0.274784   \n",
       "50005 -0.209773 -0.049465 -0.103923  0.094951  0.723268  0.081945 -0.277208   \n",
       "50006 -0.170780 -0.043606 -0.102057 -0.576460  0.723268 -0.389787 -0.274279   \n",
       "50007 -0.209773 -0.049465 -0.103923  0.094951  0.723268  0.081945 -0.277208   \n",
       "50008 -0.070533 -0.047383 -0.101459 -0.576705  0.723268 -0.389949 -0.276073   \n",
       "50009 -0.209773 -0.049465 -0.103923  0.094951  0.723268  0.081945 -0.277208   \n",
       "50010 -0.131619 -0.040150 -0.090947 -0.576569  0.723268 -0.389832 -0.266261   \n",
       "50011 -0.209773 -0.049465 -0.103923  0.094951  0.723268  0.081945 -0.277208   \n",
       "50012 -0.077206 -0.045460 -0.099454 -0.576629  0.723268 -0.389931 -0.274943   \n",
       "50013 -0.171849 -0.041409 -0.098702 -0.576352  0.723268 -0.389718 -0.268376   \n",
       "50014 -0.136713 -0.045884 -0.094442 -0.576602 -1.141901 -0.389906 -0.268890   \n",
       "50015 -0.209774 -0.049465 -0.103923  0.178922  0.723268  0.140934 -0.277208   \n",
       "50016 -0.121280 -0.042839 -0.098215 -0.576598  0.723268 -0.389880 -0.272956   \n",
       "50017  0.021835 -0.045060 -0.093063 -0.576743 -1.141901 -0.389948 -0.274117   \n",
       "50018 -0.209774 -0.049465 -0.103923  0.178922  0.723268  0.140934 -0.277208   \n",
       "50019 -0.140907 -0.042862 -0.099106 -0.576562  0.723268 -0.389854 -0.272722   \n",
       "\n",
       "          smean     dmean  ct_srv_src  ct_dst_sport_ltm  ct_dst_src_ltm  \\\n",
       "50000 -0.037873 -0.480703   -0.682570         -0.381470       -0.614256   \n",
       "50001 -0.179560 -0.480703   -0.589150         -0.381470       -0.522983   \n",
       "50002  1.637940 -0.480703   -0.775991         -0.554373       -0.614256   \n",
       "50003 -0.179560 -0.480703   -0.495729         -0.381470       -0.431710   \n",
       "50004 -0.448276 -0.306498    0.064793         -0.554373       -0.705529   \n",
       "50005 -0.179560 -0.480703   -0.495729         -0.381470       -0.431710   \n",
       "50006 -0.072073 -0.306498   -0.775991         -0.554373       -0.614256   \n",
       "50007 -0.179560 -0.480703   -0.495729         -0.381470       -0.431710   \n",
       "50008 -0.394533 -0.310369   -0.775991         -0.554373       -0.705529   \n",
       "50009 -0.179560 -0.480703   -0.495729         -0.381470       -0.431710   \n",
       "50010  0.074499  0.239345   -0.775991         -0.554373       -0.705529   \n",
       "50011 -0.179560 -0.480703   -0.495729         -0.381470       -0.431710   \n",
       "50012 -0.394533 -0.271657   -0.308889         -0.208566       -0.249164   \n",
       "50013 -0.013444 -0.116808    0.345054         -0.554373        0.207200   \n",
       "50014 -0.262618  0.177405   -0.775991         -0.554373       -0.705529   \n",
       "50015 -0.179560 -0.480703   -0.495729         -0.381470       -0.431710   \n",
       "50016 -0.116045 -0.163263   -0.308889         -0.554373       -0.249164   \n",
       "50017 -0.194217  0.123208   -0.682570         -0.554373       -0.614256   \n",
       "50018 -0.179560 -0.480703   -0.495729         -0.381470       -0.431710   \n",
       "50019 -0.116045 -0.143906   -0.308889         -0.554373       -0.249164   \n",
       "\n",
       "       ct_srv_dst     label  service  \n",
       "50000   -0.660111  0.685014        2  \n",
       "50001   -0.567147  0.685014        0  \n",
       "50002   -0.753074  0.685014        0  \n",
       "50003   -0.474184  0.685014        0  \n",
       "50004   -0.753074  0.685014        0  \n",
       "50005   -0.474184  0.685014        0  \n",
       "50006   -0.753074  0.685014        5  \n",
       "50007   -0.474184  0.685014        0  \n",
       "50008   -0.753074  0.685014        0  \n",
       "50009   -0.474184  0.685014        0  \n",
       "50010   -0.195294  0.685014        0  \n",
       "50011   -0.474184  0.685014        0  \n",
       "50012   -0.195294  0.685014        0  \n",
       "50013    0.176560  0.685014        0  \n",
       "50014   -0.753074  0.685014        5  \n",
       "50015   -0.474184  0.685014        0  \n",
       "50016   -0.288257  0.685014        0  \n",
       "50017   -0.660111  0.685014        5  \n",
       "50018   -0.474184  0.685014        0  \n",
       "50019   -0.288257  0.685014        0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import colorama\n",
    "from colorama import Fore\n",
    "\n",
    "\n",
    "while(True):\n",
    "    choice = input(Fore.BLUE+'Enter \\'single\\' for predicting single value\\nEnter \\'range\\' to predict a range of values : ')\n",
    "    if(choice=='range'):\n",
    "        print()\n",
    "        start,end = map(int,input(Fore.BLUE+'Enter the range for prediction between [0,175340]: ').split())\n",
    "        prediction = selected_test[start:end]\n",
    "        tar = test_target[start:end]\n",
    "        break\n",
    "    elif(choice=='single'):\n",
    "        predict_column = int(input(Fore.BLUE+'Enter the value between [0,175340]: '))\n",
    "        prediction = selected_test[predict_column:predict_column+1]\n",
    "        tar = test_target[predict_column:predict_column+1]\n",
    "        break\n",
    "    else:\n",
    "        print(Fore.RED+'Enter correct choice')\n",
    "        \n",
    "tar = list(tar)\n",
    "#print(tar)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e38aa67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuzzers   DoS\n",
      "Exploits   Fuzzers\n",
      "Shellcode   Shellcode\n",
      "Fuzzers   Fuzzers\n",
      "DoS   Exploits\n",
      "Reconnaissance   Fuzzers\n",
      "DoS   Exploits\n",
      "DoS   Fuzzers\n",
      "Reconnaissance   Exploits\n",
      "Exploits   Fuzzers\n",
      "Exploits   Exploits\n",
      "Exploits   Fuzzers\n",
      "Fuzzers   Fuzzers\n",
      "Fuzzers   Fuzzers\n",
      "Exploits   DoS\n",
      "Reconnaissance   Fuzzers\n",
      "Fuzzers   Fuzzers\n",
      "Exploits   Exploits\n",
      "Exploits   Fuzzers\n",
      "Fuzzers   Fuzzers\n"
     ]
    }
   ],
   "source": [
    "DTC_prediction_result = DTC_Classifier.predict(prediction)\n",
    "for i in range(len(DTC_prediction_result)):\n",
    "    print(tar[i],\" \",DTC_prediction_result[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513f755f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
